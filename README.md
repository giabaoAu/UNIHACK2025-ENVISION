# AI-Assisted Visual Chat for Blind Users

## Overview

This project is designed to help blind users capture photos of their surroundings and interact with an AI assistant that describes and discusses the captured image. The AI provides a conversational interface, allowing users to gain insights about their environment and ask follow-up questions.

## Features

- **Capture Photos**: Users can take a photo of their surroundings using the built-in camera feature.
- **AI-Powered Description**: The AI analyzes the image and provides a detailed description.
- **Conversational Chat**: Users can engage in a chat with the AI to ask questions and get more details about the scene.
- **Voice Interaction**: Speech-to-text support enables hands-free communication.
- **Accessible UI**: Designed with accessibility in mind for a seamless user experience.

## Tech Stack

- **Frontend**: React (Next.js)
- **Language**: TypeScript
- **UI Library**: Aceternity UI
- **AI Services**: Integration with an AI Model API (Google Gemini) for image analysis and chatbot functionality

## Installation & Setup

1. Clone the repository:
   ```bash
   git clone https://github.com/UNIHACK2025-SmartCompanion
   cd UNIHACK2025-SmartCompanion
   ```
2. Install dependencies:
   ```bash
   npm install
   ```
3. Start the development server:
   ```bash
   npm run dev
   ```
4. Open your browser and go to `http://localhost:3000`

## Usage

1. Open the application.
2. Capture a photo using the on-screen button.
3. The AI will analyze and describe the image.
4. Users can chat with the AI via text or voice input.
5. Users can capture another photo or continue the conversation.

## Contributing
This project was developed by: 
    1. Bao Au (LinkedIN:)
    2. Uyen Ho (LinedIN:)
    3. Hayden Ngo (LinkedIN)
    4. Hminh (LinkedIn)

## License

This project is open-source and available under the MIT License.

## Contact

For questions or support, please reach out via [your contact email or GitHub Issues].
